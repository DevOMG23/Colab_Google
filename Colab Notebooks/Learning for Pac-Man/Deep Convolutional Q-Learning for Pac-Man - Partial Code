{"cells":[{"cell_type":"markdown","metadata":{"id":"EAiHVEoWHy_D"},"source":["# Deep Convolutional Q-Learning for Pac-Man"]},{"cell_type":"markdown","metadata":{"id":"tjO1aK3Ddjs5"},"source":["## Part 0 - Installing the required packages and importing the libraries"]},{"cell_type":"markdown","metadata":{"id":"NwdRB-ZLdrAV"},"source":["### Installing Gymnasium"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54443,"status":"ok","timestamp":1714509164132,"user":{"displayName":"Omar Mora","userId":"00118441038664471102"},"user_tz":360},"id":"dbnq3XpoKa_7","outputId":"55069d22-f04b-450f-ea39-f45ac6aa7d1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in c:\\users\\omar_\\anaconda3\\lib\\site-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: gymnasium[accept-rom-license,atari] in c:\\users\\omar_\\anaconda3\\lib\\site-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n","Requirement already satisfied: autorom~=0.4.2 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (0.4.2)\n","Requirement already satisfied: shimmy<1.0,>=0.1.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]) (0.2.1)\n","Requirement already satisfied: click in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (8.1.7)\n","Requirement already satisfied: requests in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (2.31.0)\n","Requirement already satisfied: tqdm in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (4.65.0)\n","Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (0.6.1)\n","Requirement already satisfied: ale-py~=0.8.1 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]) (0.8.1)\n","Requirement already satisfied: importlib-resources in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]) (6.4.0)\n","Requirement already satisfied: colorama in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from click->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (2024.2.2)\n"]},{"output_type":"stream","name":"stderr","text":["'apt-get' is not recognized as an internal or external command,\n","operable program or batch file.\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium[box2d] in c:\\users\\omar_\\anaconda3\\lib\\site-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\omar_\\anaconda3\\lib\\site-packages (from gymnasium[box2d]) (0.0.4)\n","Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n","  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting pygame>=2.1.3 (from gymnasium[box2d])\n","  Using cached pygame-2.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n","Collecting swig==4.* (from gymnasium[box2d])\n","  Using cached swig-4.2.1-py2.py3-none-win_amd64.whl.metadata (3.7 kB)\n","Using cached swig-4.2.1-py2.py3-none-win_amd64.whl (2.6 MB)\n","Using cached pygame-2.5.2-cp311-cp311-win_amd64.whl (10.8 MB)\n","Building wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py): started\n","  Building wheel for box2d-py (setup.py): finished with status 'error'\n","  Running setup.py clean for box2d-py\n","Failed to build box2d-py\n"]},{"output_type":"stream","name":"stderr","text":["  error: subprocess-exited-with-error\n","  \n","  python setup.py bdist_wheel did not run successfully.\n","  exit code: 1\n","  \n","  [16 lines of output]\n","  Using setuptools (version 68.2.2).\n","  running bdist_wheel\n","  running build\n","  running build_py\n","  creating build\n","  creating build\\lib.win-amd64-cpython-311\n","  creating build\\lib.win-amd64-cpython-311\\Box2D\n","  copying library\\Box2D\\Box2D.py -> build\\lib.win-amd64-cpython-311\\Box2D\n","  copying library\\Box2D\\__init__.py -> build\\lib.win-amd64-cpython-311\\Box2D\n","  creating build\\lib.win-amd64-cpython-311\\Box2D\\b2\n","  copying library\\Box2D\\b2\\__init__.py -> build\\lib.win-amd64-cpython-311\\Box2D\\b2\n","  running build_ext\n","  building 'Box2D._Box2D' extension\n","  swigging Box2D\\Box2D.i to Box2D\\Box2D_wrap.cpp\n","  swig.exe -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\\Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\\Box2D_wrap.cpp Box2D\\Box2D.i\n","  error: command 'swig.exe' failed: None\n","  [end of output]\n","  \n","  note: This error originates from a subprocess, and is likely not a problem with pip.\n","  ERROR: Failed building wheel for box2d-py\n","ERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\n"]}],"source":["!pip install gymnasium\n","!pip install \"gymnasium[atari, accept-rom-license]\"\n","!apt-get install -y swig\n","!pip install gymnasium[box2d]"]},{"cell_type":"markdown","metadata":{"id":"H-wes4LZdxdd"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6697,"status":"ok","timestamp":1714508821759,"user":{"displayName":"Omar Mora","userId":"00118441038664471102"},"user_tz":360},"id":"Ho_25-9_9qnu"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from collections import deque\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"markdown","metadata":{"id":"m7wa0ft8e3M_"},"source":["## Part 1 - Building the AI"]},{"cell_type":"markdown","metadata":{"id":"dlYVpVdHe-i6"},"source":["### Creating the architecture of the Neural Network"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1714508936823,"user":{"displayName":"Omar Mora","userId":"00118441038664471102"},"user_tz":360},"id":"KETEEWPqlPkl"},"outputs":[],"source":["class Network(nn.Module):\n","\n","  def __init__(self, action_size, seed = 42):\n","    super(Network, self).__init__()\n","    self.seed = torch.manual_seed(seed)\n","    self.conv1 = nn.Conv2d(3, 32, kernel_size = 8, stride = 4)\n","    self.bn1 = nn.BatchNorm2d(32)\n","    self.conv2 = nn.Conv2d(32, 64, kernel_size = 4, stride = 2)\n","    self.bn2 = nn.BatchNorm2d(64)\n","    self.conv3 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1)\n","    self.bn3 = nn.BatchNorm2d(64)\n","    self.conv4 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1)\n","    self.bn4 = nn.BatchNorm2d(128)\n","    self.fc1 = nn.Linear(10 * 10 * 128, 512)\n","    self.fc2 = nn.Linear(512, 256)\n","    self.fc3 = nn.Linear(256, action_size)\n","\n","  def forward(self, state):\n","    x = F.relu(self.bn1(self.conv1(state)))\n","    x = F.relu(self.bn2(self.conv2(x)))\n","    x = F.relu(self.bn3(self.conv3(x)))\n","    x = F.relu(self.bn4(self.conv4(x)))\n","    x = x.view(x.size(0), -1)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    return self.fc3(x)"]},{"cell_type":"markdown","metadata":{"id":"rUvCfE_mhwo2"},"source":["## Part 2 - Training the AI"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1568,"status":"ok","timestamp":1714508948440,"user":{"displayName":"Omar Mora","userId":"00118441038664471102"},"user_tz":360},"id":"Yrq6fmRszu3D","outputId":"72a492bd-3fc3-489c-d618-62cb1a563cd8"},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\omar_\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment MsPacmanDeterministic-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  logger.deprecation(\n"]},{"output_type":"stream","name":"stdout","text":["State shape:  (210, 160, 3)\n","State size:  210\n","Number of actions:  9\n"]}],"source":["import gymnasium as gym\n","env = gym.make('MsPacmanDeterministic-v0', full_action_space = False)\n","state_shape = env.observation_space.shape\n","state_size = env.observation_space.shape[0]\n","number_actions = env.action_space.n\n","print('State shape: ', state_shape)\n","print('State size: ', state_size)\n","print('Number of actions: ', number_actions)"]},{"cell_type":"markdown","metadata":{"id":"WWCDPF22lkwc"},"source":["### Setting up the environment"]},{"cell_type":"markdown","metadata":{"id":"Bx6IdX3ciDqH"},"source":["### Initializing the hyperparameters"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1714508952454,"user":{"displayName":"Omar Mora","userId":"00118441038664471102"},"user_tz":360},"id":"CvGOkgAK12cE"},"outputs":[],"source":["learning_rate = 5e-4\n","minibatch_size = 64\n","discount_factor = 0.99"]},{"cell_type":"markdown","metadata":{"id":"U2bDShIEkA5V"},"source":["### Preprocessing the frames"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1059,"status":"error","timestamp":1714508960193,"user":{"displayName":"Omar Mora","userId":"00118441038664471102"},"user_tz":360},"id":"JcI_DR0V2-jK","colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"8d6b8882-7ebe-4303-cc6b-bb0f3fbe86d6"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torchvision'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_frame\u001b[39m(frame):\n\u001b[0;32m      5\u001b[0m   frame \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(frame)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"]}],"source":["from PIL import Image\n","from torchvision import transforms\n","\n","def preprocess_frame(frame):\n","  frame = Image.fromarray(frame)\n","  preprocess = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n","  return preprocess(frame).unsqueeze(0)"]},{"cell_type":"markdown","metadata":{"id":"imMdSO-HAWra"},"source":["### Implementing the DCQN class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0-ey-ZF54qV"},"outputs":[],"source":["class Agent():\n","\n","  def __init__(self, action_size):\n","    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    self.action_size = action_size\n","    self.local_qnetwork = Network(action_size).to(self.device)\n","    self.target_qnetwork = Network(action_size).to(self.device)\n","    self.optimizer = optim.Adam(self.local_qnetwork.parameters(), lr = learning_rate)\n","    self.memory = deque(maxlen = 10000)\n","\n","  def step(self, state, action, reward, next_state, done):\n","    state = preprocess_frame(state)\n","    next_state = preprocess_frame(next_state)\n","    self.memory.append((state, action, reward, next_state, done))\n","    if len(self.memory) > minibatch_size:\n","      experiences = random.sample(self.memory, k = minibatch_size)\n","      self.learn(experiences, discount_factor)\n","\n","  def act(self, state, epsilon = 0.):\n","    state = preprocess_frame(state).to(self.device)\n","    self.local_qnetwork.eval()\n","    with torch.no_grad():\n","      action_values = self.local_qnetwork(state)\n","    self.local_qnetwork.train()\n","    if random.random() > epsilon:\n","      return np.argmax(action_values.cpu().data.numpy())\n","    else:\n","      return random.choice(np.arange(self.action_size))\n","\n","  def learn(self, experiences, discount_factor):\n","    states, actions, rewards, next_states, dones = zip(*experiences)\n","    states = torch.from_numpy(np.vstack(states)).float().to(self.device)\n","    actions = torch.from_numpy(np.vstack(actions)).long().to(self.device)\n","    rewards = torch.from_numpy(np.vstack(rewards)).float().to(self.device)\n","    next_states = torch.from_numpy(np.vstack(next_states)).float().to(self.device)\n","    dones = torch.from_numpy(np.vstack(dones).astype(np.uint8)).float().to(self.device)\n","    next_q_targets = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n","    q_targets = rewards + discount_factor * next_q_targets * (1 - dones)\n","    q_expected = self.local_qnetwork(states).gather(1, actions)\n","    loss = F.mse_loss(q_expected, q_targets)\n","    self.optimizer.zero_grad()\n","    loss.backward()\n","    self.optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"yUg95iBpAwII"},"source":["### Initializing the DCQN agent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qM1jMQ5s_HC2"},"outputs":[],"source":["agent = Agent(number_actions)"]},{"cell_type":"markdown","metadata":{"id":"CK6Zt_gNmHvm"},"source":["### Training the DCQN agent"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"MbeFdaDx_4Uj","outputId":"0f9f6cea-3f39-4a6d-881a-6f481e7fe8c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode 6\tAverage Score: 236.67"]}],"source":["number_episodes = 2000\n","maximum_number_timesteps_per_episode = 10000\n","epsilon_starting_value  = 1.0\n","epsilon_ending_value  = 0.01\n","epsilon_decay_value  = 0.995\n","epsilon = epsilon_starting_value\n","scores_on_100_episodes = deque(maxlen = 100)\n","\n","for episode in range(1, number_episodes + 1):\n","  state, _ = env.reset()\n","  score = 0\n","  for t in range(maximum_number_timesteps_per_episode):\n","    action = agent.act(state, epsilon)\n","    next_state, reward, done, _, _ = env.step(action)\n","    agent.step(state, action, reward, next_state, done)\n","    state = next_state\n","    score += reward\n","    if done:\n","      break\n","  scores_on_100_episodes.append(score)\n","  epsilon = max(epsilon_ending_value, epsilon_decay_value * epsilon)\n","  print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)), end = \"\")\n","  if episode % 100 == 0:\n","    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode, np.mean(scores_on_100_episodes)))\n","  if np.mean(scores_on_100_episodes) >= 500.0:\n","    print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode - 100, np.mean(scores_on_100_episodes)))\n","    torch.save(agent.local_qnetwork.state_dict(), 'checkpoint.pth')\n","    break"]},{"cell_type":"markdown","metadata":{"id":"-0WhhBV8nQdf"},"source":["## Part 3 - Visualizing the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb9nVvU2Okhk"},"outputs":[],"source":["import glob\n","import io\n","import base64\n","import imageio\n","from IPython.display import HTML, display\n","from gym.wrappers.monitoring.video_recorder import VideoRecorder\n","\n","def show_video_of_model(agent, env_name):\n","    env = gym.make(env_name, render_mode='rgb_array')\n","    state, _ = env.reset()\n","    done = False\n","    frames = []\n","    while not done:\n","        frame = env.render()\n","        frames.append(frame)\n","        action = agent.act(state)\n","        state, reward, done, _, _ = env.step(action)\n","    env.close()\n","    imageio.mimsave('video.mp4', frames, fps=30)\n","\n","show_video_of_model(agent, 'MsPacmanDeterministic-v0')\n","\n","def show_video():\n","    mp4list = glob.glob('*.mp4')\n","    if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"Could not find video\")\n","\n","show_video()"]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1nqb-KnVe1EsZF-03Iba7T3cZFsnVRl4H","timestamp":1695853702757}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}