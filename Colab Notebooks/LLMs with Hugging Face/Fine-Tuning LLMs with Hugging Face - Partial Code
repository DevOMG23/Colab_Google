{"cells":[{"cell_type":"markdown","metadata":{"id":"WVa0caPZlogN"},"source":["# Fine-Tuning LLMs with Hugging Face"]},{"cell_type":"markdown","metadata":{"id":"fT5BjFcflZAh"},"source":["## Step 1: Installing and importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLXwJqbjtPho"},"outputs":[],"source":["!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRZm_OAbs3qA"},"outputs":[],"source":["!pip install huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAMzy_0FtaUZ"},"outputs":[],"source":["import torch\n","from trl import SFTTrainer\n","from peft import LoraConfig\n","from datasets import load_dataset\n","from transformers import (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline)"]},{"cell_type":"markdown","metadata":{"id":"rz3vMSzhs-P7"},"source":["## Step 2: Loading the model"]},{"cell_type":"code","source":["llama_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path = \"aboonaji/llama2finetune-v2\",\n","                                                   quantization_config = BitsAndBytesConfig(load_in_4bit = True, bnb_4bit_compute_dtype = getattr(torch, \"float16\"), bnb_4bit_quant_type = \"nf4\"))\n","llama_model.config.use_cache = False\n","llama_model.config.pretraining_tp = 1"],"metadata":{"id":"922r6VXVrRkG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g6aWb1e7tNRS"},"source":["## Step 3: Loading the tokenizer"]},{"cell_type":"code","source":["llama_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path = \"aboonaji/llama2finetune-v2\", trust_remote_code = True)\n","llama_tokenizer.pad_token = llama_tokenizer.eos_token\n","llama_tokenizer.padding_side = \"right\""],"metadata":{"id":"9oaxbcmRwmFi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"coUlIR-ytjiF"},"source":["## Step 4: Setting the training arguments"]},{"cell_type":"code","source":["training_arguments = TrainingArguments(output_dir = \"./results\", per_device_train_batch_size = 4, max_steps = 100)"],"metadata":{"id":"4a7BlWbsxQg2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0RGLZtFwHQiZ"},"source":["## Step 5: Creating the Supervised Fine-Tuning trainer"]},{"cell_type":"code","source":["llama_sft_trainer = SFTTrainer(model = llama_model,\n","                               args = training_arguments,\n","                               train_dataset = load_dataset(path = \"aboonaji/wiki_medical_terms_llam2_format\", split = \"train\"),\n","                               tokenizer = llama_tokenizer,\n","                               peft_config = LoraConfig(task_type = \"CAUSAL_LM\", r = 64, lora_alpha = 16, lora_dropout = 0.1),\n","                               dataset_text_field = \"text\")"],"metadata":{"id":"_XUPycVCzBik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oSF8SHFKt1xL"},"source":["## Step 6: Training the model"]},{"cell_type":"code","source":["llama_sft_trainer.train()"],"metadata":{"id":"i7s6v2Pw07al"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XMPw6WU6vbjP"},"source":["## Step 7: Chatting with the model"]},{"cell_type":"code","source":["user_prompt = \"Please tell me about Bursitis\"\n","text_generation_pipeline = pipeline(task = \"text-generation\", model = llama_model, tokenizer = llama_tokenizer, max_length = 300)\n","model_answer = text_generation_pipeline(f\"<s>[INST] {user_prompt} [/INST]\")\n","print(model_answer[0]['generated_text'])"],"metadata":{"id":"dj_sw6PM0_4_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1QdRqUg52KXlZM6H95ALtkgsLhoUJbfqY","timestamp":1700598650361},{"file_id":"1yo2NTyRaTTr0JJ4TCIqPunY2M8Dw7tOh","timestamp":1699244453424},{"file_id":"1_49KfvLBoF85Isc4Gdoyw28Oxxdpv6Eo","timestamp":1693751472053},{"file_id":"1s1ku_N8OJPKBluQBrpcZ7AkfdAcZ_Q12","timestamp":1692693138968},{"file_id":"1578XncaDK8vPWB3kLgw410DQNCqnZVec","timestamp":1692609627275},{"file_id":"1R3-kNFWLKu7tkgOM-mD99mm2nGD5-9Lh","timestamp":1692597817214},{"file_id":"1WVSL4serOfoXztXlNQLaaUQUjeufz9SF","timestamp":1692590287814},{"file_id":"1gaFqTnMarV6oTFgtPtxVudyiiXSlC845","timestamp":1692542130771},{"file_id":"1Rem8wniY65tq9Z0W5AdDfhUtm-yFpVuX","timestamp":1692463431916},{"file_id":"1SZSeXt3LCYrzjCEfWLuUd1vZadLm4v01","timestamp":1692341216495},{"file_id":"1hbd_kGydA8pKAYuqlKUXMOw6YJEhv4Tz","timestamp":1691472982802},{"file_id":"1YoUr7SPQrbBW3ubPpofTIb-99EdQv5S0","timestamp":1691423558809},{"file_id":"1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd","timestamp":1691305989771}],"private_outputs":true,"cell_execution_strategy":"setup"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}